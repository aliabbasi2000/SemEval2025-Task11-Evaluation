{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in /Users/abumafrim/miniconda3/envs/datascience/lib/python3.9/site-packages (from -r requirements.txt (line 1)) (1.12.0)\n",
      "Requirement already satisfied: numpy in /Users/abumafrim/miniconda3/envs/datascience/lib/python3.9/site-packages (from -r requirements.txt (line 2)) (1.26.0)\n",
      "Requirement already satisfied: tabulate2 in /Users/abumafrim/miniconda3/envs/datascience/lib/python3.9/site-packages (from -r requirements.txt (line 3)) (1.9.1)\n",
      "Requirement already satisfied: scikit-learn in /Users/abumafrim/miniconda3/envs/datascience/lib/python3.9/site-packages (from -r requirements.txt (line 4)) (1.4.1.post1)\n",
      "Requirement already satisfied: wcwidth>=0.2.13 in /Users/abumafrim/miniconda3/envs/datascience/lib/python3.9/site-packages (from tabulate2->-r requirements.txt (line 3)) (0.2.13)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/abumafrim/miniconda3/envs/datascience/lib/python3.9/site-packages (from scikit-learn->-r requirements.txt (line 4)) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/abumafrim/miniconda3/envs/datascience/lib/python3.9/site-packages (from scikit-learn->-r requirements.txt (line 4)) (3.3.0)\n"
     ]
    }
   ],
   "source": [
    "# install dependencies and clone or update the shared task repository\n",
    "!bash settings.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============\n",
      "Checklist:\n",
      "==============\n",
      "+------------------+----------+----------------------------------+\n",
      "| Item             | Status   | Comment                          |\n",
      "+==================+==========+==================================+\n",
      "| Submission file. | Pass     | Found valid file: pred_deu_a.csv |\n",
      "+------------------+----------+----------------------------------+\n",
      "| File format.     | Pass     | CSV file.                        |\n",
      "+------------------+----------+----------------------------------+\n",
      "| Language code.   | Pass     | Language code: deu               |\n",
      "+------------------+----------+----------------------------------+\n",
      "| Task name.       | Pass     | Task: A                          |\n",
      "+------------------+----------+----------------------------------+\n",
      "\n",
      "Zipping the submission file...\n",
      "Zipped file: /Users/abumafrim/Downloads/pred_deu_a.zip is ready for upload in the codabench submission page.\n",
      "\n",
      "Gold data file not found.\n"
     ]
    }
   ],
   "source": [
    "!python3 check_submission.py \\\n",
    "  -s /Users/abumafrim/Downloads/pred_deu_a.csv \\\n",
    "  -p dev \\\n",
    "  --zip_for_submission \\\n",
    "  --evaluate \\\n",
    "  -g /Users/abumafrim/Downloads/example_gold_deu_a.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation for Participants:\n",
    "\n",
    "- **`-s` (Submission file)**: This is the path to the submission file you're trying to check. It should follow the format `pred_<language_code>_<task>.csv` (e.g., `pred_deu_a.csv` for German, track 'a').\n",
    "\n",
    "- **`-p` (Phase)**: Defines the phase of the competition you're in, either 'dev' for development or 'test' for test submissions.\n",
    "\n",
    "- **`--zip_for_submission`**: This flag will zip the submission file into a `.zip` file after it's validated and/or evaluated. It is helpful when preparing the file for upload to the competition platform.\n",
    "\n",
    "- **`--evaluate`**: This flag instructs the script to evaluate the submission file by comparing it with the provided gold standard file. It will generate evaluation metrics such as precision, recall, and F1 score.\n",
    "\n",
    "- **`-g` (Gold data file)**: This is the path to the gold data file, which contains the correct labels. This is necessary for evaluation, and the script will compare your submission to this file to compute the evaluation metrics.\n",
    "\n",
    "### Additional Notes for Participants:\n",
    "- If you are not ready to evaluate your submission or do not have a gold file, you can omit the `--evaluate` and `-g` arguments.\n",
    "- The zipped file will be created if you use the `--zip_for_submission` flag, and it will be ready for upload to the competition platform.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
